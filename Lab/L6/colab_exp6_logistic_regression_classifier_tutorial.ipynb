{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBnx7g6LDvCC"
      },
      "source": [
        "<a class=\"anchor\" id=\"0\"></a>\n",
        "# **Logistic Regression Classifier Tutorial with Python**\n",
        "\n",
        "\n",
        "Hello friends,\n",
        "\n",
        "\n",
        "In this kernel, I implement Logistic Regression with Python and Scikit-Learn. I build a Logistic Regression classifier to predict whether or not it will rain tomorrow in Australia. I train a binary classification model using Logistic Regression. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2BVW9KYDvCG"
      },
      "source": [
        "**As always, I hope you find this kernel useful and your <font color=\"red\"><b>UPVOTES</b></font> would be highly appreciated**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcxdCY71DvCH"
      },
      "source": [
        "<a class=\"anchor\" id=\"0.1\"></a>\n",
        "# **Table of Contents**\n",
        "\n",
        "\n",
        "1.\t[Introduction to Logistic Regression](#1)\n",
        "2.\t[Logistic Regression intuition](#2)\n",
        "3.\t[Assumptions of Logistic Regression](#3)\n",
        "4.\t[Types of Logistic Regression](#4)\n",
        "5.\t[Import libraries](#5)\n",
        "6.\t[Import dataset](#6)\n",
        "7.\t[Exploratory data analysis](#7)\n",
        "8.\t[Declare feature vector and target variable](#8)\n",
        "9.\t[Split data into separate training and test set](#9)\n",
        "10.\t[Feature engineering](#10)\n",
        "11.\t[Feature scaling](#11)\n",
        "12.\t[Model training](#12)\n",
        "13.\t[Predict results](#13)\n",
        "14.\t[Check accuracy score](#14)\n",
        "15.\t[Confusion matrix](#15)\n",
        "16.\t[Classification metrices](#16)\n",
        "17.\t[Adjusting the threshold level](#17)\n",
        "18.\t[ROC - AUC](#18)\n",
        "19.\t[k-Fold Cross Validation](#19)\n",
        "20.\t[Hyperparameter optimization using GridSearch CV](#20)\n",
        "21.\t[Results and conclusion](#21)\n",
        "22. [References](#22)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UliNarDDvCH"
      },
      "source": [
        "# **1. Introduction to Logistic Regression** <a class=\"anchor\" id=\"1\"></a>\n",
        "\n",
        "\n",
        "[Table of Contents](#0.1)\n",
        "\n",
        "\n",
        "When data scientists may come across a new classification problem, the first algorithm that may come across their mind is **Logistic Regression**. It is a supervised learning classification algorithm which is used to predict observations to a discrete set of classes. Practically, it is used to classify observations into different categories. Hence, its output is discrete in nature. **Logistic Regression** is also called **Logit Regression**. It is one of the most simple, straightforward and versatile classification algorithms which is used to solve classification problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V43TGWMBDvCI"
      },
      "source": [
        "# **2. Logistic Regression intuition** <a class=\"anchor\" id=\"2\"></a>\n",
        "\n",
        "\n",
        "[Table of Contents](#0.1)\n",
        "\n",
        "\n",
        "In statistics, the **Logistic Regression model** is a widely used statistical model which is primarily used for classification purposes. It means that given a set of observations, Logistic Regression algorithm helps us to classify these observations into two or more discrete classes. So, the target variable is discrete in nature.\n",
        "\n",
        "\n",
        "The Logistic Regression algorithm works as follows -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrUzXcbjDvCI"
      },
      "source": [
        "## **Implement linear equation**\n",
        "\n",
        "\n",
        "Logistic Regression algorithm works by implementing a linear equation with independent or explanatory variables to predict a response value. For example, we consider the example of number of hours studied and probability of passing the exam. Here, number of hours studied is the explanatory variable and it is denoted by x1. Probability of passing the exam is the response or target variable and it is denoted by z.\n",
        "\n",
        "\n",
        "If we have one explanatory variable (x1) and one response variable (z), then the linear equation would be given mathematically with the following equation-\n",
        "\n",
        "    z = β0 + β1x1    \n",
        "\n",
        "Here, the coefficients β0 and β1 are the parameters of the model.\n",
        "\n",
        "\n",
        "If there are multiple explanatory variables, then the above equation can be extended to\n",
        "\n",
        "    z = β0 + β1x1+ β2x2+……..+ βnxn\n",
        "    \n",
        "Here, the coefficients β0, β1, β2 and βn are the parameters of the model.\n",
        "\n",
        "So, the predicted response value is given by the above equations and is denoted by z."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weGKVF4tDvCJ"
      },
      "source": [
        "## **Sigmoid Function**\n",
        "\n",
        "This predicted response value, denoted by z is then converted into a probability value that lie between 0 and 1. We use the sigmoid function in order to map predicted values to probability values. This sigmoid function then maps any real value into a probability value between 0 and 1.\n",
        "\n",
        "In machine learning, sigmoid function is used to map predictions to probabilities. The sigmoid function has an S shaped curve. It is also called sigmoid curve.\n",
        "\n",
        "A Sigmoid function is a special case of the Logistic function. It is given by the following mathematical formula.\n",
        "\n",
        "Graphically, we can represent sigmoid function with the following graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3BnpNCTDvCK"
      },
      "source": [
        "### Sigmoid Function\n",
        "\n",
        "![Sigmoid Function](https://miro.medium.com/max/970/1*Xu7B5y9gp0iL5ooBj7LtWw.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPwLv6dSDvCK"
      },
      "source": [
        "## **Decision boundary**\n",
        "\n",
        "The sigmoid function returns a probability value between 0 and 1. This probability value is then mapped to a discrete class which is either “0” or “1”. In order to map this probability value to a discrete class (pass/fail, yes/no, true/false), we select a threshold value. This threshold value is called Decision boundary. Above this threshold value, we will map the probability values into class 1 and below which we will map values into class 0.\n",
        "\n",
        "Mathematically, it can be expressed as follows:-\n",
        "\n",
        "p ≥ 0.5 => class = 1\n",
        "\n",
        "p < 0.5 => class = 0 \n",
        "\n",
        "Generally, the decision boundary is set to 0.5. So, if the probability value is 0.8 (> 0.5), we will map this observation to class 1. Similarly, if the probability value is 0.2 (< 0.5), we will map this observation to class 0. This is represented in the graph below-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okQsT3uUDvCL"
      },
      "source": [
        "![Decision boundary in sigmoid function](https://ml-cheatsheet.readthedocs.io/en/latest/_images/logistic_regression_sigmoid_w_threshold.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldoWQnXLDvCL"
      },
      "source": [
        "## **Making predictions**\n",
        "\n",
        "Now, we know about sigmoid function and decision boundary in logistic regression. We can use our knowledge of sigmoid function and decision boundary to write a prediction function. A prediction function in logistic regression returns the probability of the observation being positive, Yes or True. We call this as class 1 and it is denoted by P(class = 1). If the probability inches closer to one, then we will be more confident about our model that the observation is in class 1, otherwise it is in class 0.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RLGVzzbDvCL"
      },
      "source": [
        "# **3. Assumptions of Logistic Regression** <a class=\"anchor\" id=\"3\"></a>\n",
        "\n",
        "\n",
        "[Table of Contents](#0.1)\n",
        "\n",
        "\n",
        "The Logistic Regression model requires several key assumptions. These are as follows:-\n",
        "\n",
        "1. Logistic Regression model requires the dependent variable to be binary, multinomial or ordinal in nature.\n",
        "\n",
        "2. It requires the observations to be independent of each other. So, the observations should not come from repeated measurements.\n",
        "\n",
        "3. Logistic Regression algorithm requires little or no multicollinearity among the independent variables. It means that the independent variables should not be too highly correlated with each other.\n",
        "\n",
        "4. Logistic Regression model assumes linearity of independent variables and log odds.\n",
        "\n",
        "5. The success of Logistic Regression model depends on the sample sizes. Typically, it requires a large sample size to achieve the high accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkW5hJFiDvCM"
      },
      "source": [
        "# **4. Types of Logistic Regression** <a class=\"anchor\" id=\"4\"></a>\n",
        "\n",
        "\n",
        "[Table of Contents](#0.1)\n",
        "\n",
        "\n",
        "Logistic Regression model can be classified into three groups based on the target variable categories. These three groups are described below:-\n",
        "\n",
        "### 1. Binary Logistic Regression\n",
        "\n",
        "In Binary Logistic Regression, the target variable has two possible categories. The common examples of categories are yes or no, good or bad, true or false, spam or no spam and pass or fail.\n",
        "\n",
        "\n",
        "### 2. Multinomial Logistic Regression\n",
        "\n",
        "In Multinomial Logistic Regression, the target variable has three or more categories which are not in any particular order. So, there are three or more nominal categories. The examples include the type of categories of fruits - apple, mango, orange and banana.\n",
        "\n",
        "\n",
        "### 3. Ordinal Logistic Regression\n",
        "\n",
        "In Ordinal Logistic Regression, the target variable has three or more ordinal categories. So, there is intrinsic order involved with the categories. For example, the student performance can be categorized as poor, average, good and excellent.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzbz-_9sDvCM"
      },
      "source": [
        "# **Import libraries** <a class=\"anchor\" id=\"5\"></a>\n",
        "\n",
        "\n",
        "[Table of Contents](#0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFAbQJB9DvCM",
        "outputId": "d3d91305-4341-4567-c84c-4812bac1a1a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/kaggle/input/weather-dataset-rattle-package/weatherAUS.csv\n"
          ]
        }
      ],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt # data visualization\n",
        "import seaborn as sns # statistical data visualization\n",
        "%matplotlib inline\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpWke19gDvCO"
      },
      "source": [
        "# **Import dataset** <a class=\"anchor\" id=\"6\"></a>\n",
        "\n",
        "\n",
        "[Table of Contents](#0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3qJSGWNDvCO"
      },
      "outputs": [],
      "source": [
        "data = '/kaggle/input/weather-dataset-rattle-package/weatherAUS.csv'\n",
        "\n",
        "df = pd.read_csv(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NiMiS4CDvCO"
      },
      "source": [
        "# **Exploratory data analysis** <a class=\"anchor\" id=\"7\"></a>\n",
        "\n",
        "\n",
        "[Table of Contents](#0.1)\n",
        "\n",
        "\n",
        "Now, I will explore the data to gain insights about the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QDTr5-TDvCO",
        "outputId": "9a43f401-cf2c-4e86-8193-327fdea801e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(142193, 24)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# view dimensions of dataset\n",
        "\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBnWGDMZDvCP"
      },
      "source": [
        "We can see that there are 142193 instances and 24 variables in the data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaDydLcFDvCP",
        "outputId": "67cbbc97-3481-4e09-f473-1e62779a1ccd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Location</th>\n",
              "      <th>MinTemp</th>\n",
              "      <th>MaxTemp</th>\n",
              "      <th>Rainfall</th>\n",
              "      <th>Evaporation</th>\n",
              "      <th>Sunshine</th>\n",
              "      <th>WindGustDir</th>\n",
              "      <th>WindGustSpeed</th>\n",
              "      <th>WindDir9am</th>\n",
              "      <th>...</th>\n",
              "      <th>Humidity3pm</th>\n",
              "      <th>Pressure9am</th>\n",
              "      <th>Pressure3pm</th>\n",
              "      <th>Cloud9am</th>\n",
              "      <th>Cloud3pm</th>\n",
              "      <th>Temp9am</th>\n",
              "      <th>Temp3pm</th>\n",
              "      <th>RainToday</th>\n",
              "      <th>RISK_MM</th>\n",
              "      <th>RainTomorrow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2008-12-01</td>\n",
              "      <td>Albury</td>\n",
              "      <td>13.4</td>\n",
              "      <td>22.9</td>\n",
              "      <td>0.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>W</td>\n",
              "      <td>44.0</td>\n",
              "      <td>W</td>\n",
              "      <td>...</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1007.7</td>\n",
              "      <td>1007.1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.9</td>\n",
              "      <td>21.8</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2008-12-02</td>\n",
              "      <td>Albury</td>\n",
              "      <td>7.4</td>\n",
              "      <td>25.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>WNW</td>\n",
              "      <td>44.0</td>\n",
              "      <td>NNW</td>\n",
              "      <td>...</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1010.6</td>\n",
              "      <td>1007.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17.2</td>\n",
              "      <td>24.3</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2008-12-03</td>\n",
              "      <td>Albury</td>\n",
              "      <td>12.9</td>\n",
              "      <td>25.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>WSW</td>\n",
              "      <td>46.0</td>\n",
              "      <td>W</td>\n",
              "      <td>...</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1007.6</td>\n",
              "      <td>1008.7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>23.2</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2008-12-04</td>\n",
              "      <td>Albury</td>\n",
              "      <td>9.2</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NE</td>\n",
              "      <td>24.0</td>\n",
              "      <td>SE</td>\n",
              "      <td>...</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1017.6</td>\n",
              "      <td>1012.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18.1</td>\n",
              "      <td>26.5</td>\n",
              "      <td>No</td>\n",
              "      <td>1.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2008-12-05</td>\n",
              "      <td>Albury</td>\n",
              "      <td>17.5</td>\n",
              "      <td>32.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>W</td>\n",
              "      <td>41.0</td>\n",
              "      <td>ENE</td>\n",
              "      <td>...</td>\n",
              "      <td>33.0</td>\n",
              "      <td>1010.8</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>29.7</td>\n",
              "      <td>No</td>\n",
              "      <td>0.2</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
              "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
              "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
              "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
              "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
              "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
              "\n",
              "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity3pm  Pressure9am  \\\n",
              "0           W           44.0          W  ...        22.0       1007.7   \n",
              "1         WNW           44.0        NNW  ...        25.0       1010.6   \n",
              "2         WSW           46.0          W  ...        30.0       1007.6   \n",
              "3          NE           24.0         SE  ...        16.0       1017.6   \n",
              "4           W           41.0        ENE  ...        33.0       1010.8   \n",
              "\n",
              "   Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  RISK_MM  \\\n",
              "0       1007.1       8.0       NaN     16.9     21.8         No      0.0   \n",
              "1       1007.8       NaN       NaN     17.2     24.3         No      0.0   \n",
              "2       1008.7       NaN       2.0     21.0     23.2         No      0.0   \n",
              "3       1012.8       NaN       NaN     18.1     26.5         No      1.0   \n",
              "4       1006.0       7.0       8.0     17.8     29.7         No      0.2   \n",
              "\n",
              "   RainTomorrow  \n",
              "0            No  \n",
              "1            No  \n",
              "2            No  \n",
              "3            No  \n",
              "4            No  \n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# preview the dataset\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8pqlwCZDvCP",
        "outputId": "082f8eb4-4195-4786-c9ef-ebfcdbec0dd7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation',\n",
              "       'Sunshine', 'WindGustDir', 'WindGustSpeed', 'WindDir9am', 'WindDir3pm',\n",
              "       'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm',\n",
              "       'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am',\n",
              "       'Temp3pm', 'RainToday', 'RISK_MM', 'RainTomorrow'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "col_names = df.columns\n",
        "\n",
        "col_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK6_YYO6DvCQ"
      },
      "source": [
        "### Types of variables\n",
        "\n",
        "\n",
        "In this section, I segregate the dataset into categorical and numerical variables. There are a mixture of categorical and numerical variables in the dataset. Categorical variables have data type object. Numerical variables have data type float64.\n",
        "\n",
        "\n",
        "First of all, I will find categorical variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_kppvdWDvCQ",
        "outputId": "08363e6e-787f-45d5-fd4f-f46b559343f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 7 categorical variables\n",
            "\n",
            "The categorical variables are : ['Date', 'Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow']\n"
          ]
        }
      ],
      "source": [
        "# find categorical variables\n",
        "\n",
        "categorical = [var for var in df.columns if df[var].dtype=='O']\n",
        "\n",
        "print('There are {} categorical variables\\n'.format(len(categorical)))\n",
        "\n",
        "print('The categorical variables are :', categorical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2iCn3rSDvCQ",
        "outputId": "ff326c7f-8f47-4055-9f56-8e89b7a2b1ab"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Location</th>\n",
              "      <th>WindGustDir</th>\n",
              "      <th>WindDir9am</th>\n",
              "      <th>WindDir3pm</th>\n",
              "      <th>RainToday</th>\n",
              "      <th>RainTomorrow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2008-12-01</td>\n",
              "      <td>Albury</td>\n",
              "      <td>W</td>\n",
              "      <td>W</td>\n",
              "      <td>WNW</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2008-12-02</td>\n",
              "      <td>Albury</td>\n",
              "      <td>WNW</td>\n",
              "      <td>NNW</td>\n",
              "      <td>WSW</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2008-12-03</td>\n",
              "      <td>Albury</td>\n",
              "      <td>WSW</td>\n",
              "      <td>W</td>\n",
              "      <td>WSW</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2008-12-04</td>\n",
              "      <td>Albury</td>\n",
              "      <td>NE</td>\n",
              "      <td>SE</td>\n",
              "      <td>E</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2008-12-05</td>\n",
              "      <td>Albury</td>\n",
              "      <td>W</td>\n",
              "      <td>ENE</td>\n",
              "      <td>NW</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date Location WindGustDir WindDir9am WindDir3pm RainToday  \\\n",
              "0  2008-12-01   Albury           W          W        WNW        No   \n",
              "1  2008-12-02   Albury         WNW        NNW        WSW        No   \n",
              "2  2008-12-03   Albury         WSW          W        WSW        No   \n",
              "3  2008-12-04   Albury          NE         SE          E        No   \n",
              "4  2008-12-05   Albury           W        ENE         NW        No   \n",
              "\n",
              "  RainTomorrow  \n",
              "0           No  \n",
              "1           No  \n",
              "2           No  \n",
              "3           No  \n",
              "4           No  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# view the categorical variables\n",
        "\n",
        "df[categorical].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhLnUq5rDvCQ"
      },
      "source": [
        "### Summary of categorical variables\n",
        "\n",
        "\n",
        "- There is a date variable. It is denoted by `Date` column.\n",
        "\n",
        "\n",
        "- There are 6 categorical variables. These are given by `Location`, `WindGustDir`, `WindDir9am`, `WindDir3pm`, `RainToday` and  `RainTomorrow`.\n",
        "\n",
        "\n",
        "- There are two binary categorical variables - `RainToday` and  `RainTomorrow`.\n",
        "\n",
        "\n",
        "- `RainTomorrow` is the target variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8ipyhyYDvCe"
      },
      "source": [
        "# **Declare feature vector and target variable** <a class=\"anchor\" id=\"8\"></a>\n",
        "\n",
        "\n",
        "[Table of Contents](#0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9KU6W7tDvCe"
      },
      "outputs": [],
      "source": [
        "X = df.drop(['RainTomorrow'], axis=1)\n",
        "\n",
        "y = df['RainTomorrow']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98xbiZ_iDvCe"
      },
      "source": [
        "# **Split data into separate training and test set** <a class=\"anchor\" id=\"9\"></a>\n",
        "\n",
        "\n",
        "[Table of Contents](#0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dan7RYjnDvCf"
      },
      "outputs": [],
      "source": [
        "# split X and y into training and testing sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0X3yDdCTDvCf",
        "outputId": "da3e35f8-1a1f-43bd-c6a8-538fe5c870f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((113754, 24), (28439, 24))"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check the shape of X_train and X_test\n",
        "\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu2dvRB0DvCn"
      },
      "source": [
        "# **Model training** <a class=\"anchor\" id=\"12\"></a>\n",
        "\n",
        "\n",
        "[Table of Contents](#0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmsWpCO1DvCn",
        "outputId": "31a6fdfc-c9dc-48b9-9ff7-0b81e920d898"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
              "                   random_state=0, solver='liblinear', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# train a logistic regression model on the training set\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "# instantiate the model\n",
        "logreg = LogisticRegression(solver='liblinear', random_state=0)\n",
        "\n",
        "\n",
        "# fit the model\n",
        "logreg.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfjsTVwIDvCn"
      },
      "source": [
        "# **Predict results** <a class=\"anchor\" id=\"13\"></a>\n",
        "\n",
        "\n",
        "[Table of Contents](#0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3pORZKvDvCn",
        "outputId": "bf64b46c-f420-4576-cc90-4f8f465101a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['No', 'No', 'No', ..., 'No', 'No', 'Yes'], dtype=object)"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_test = logreg.predict(X_test)\n",
        "\n",
        "y_pred_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54ABrf9JDvCn"
      },
      "source": [
        "### predict_proba method\n",
        "\n",
        "\n",
        "**predict_proba** method gives the probabilities for the target variable(0 and 1) in this case, in array form.\n",
        "\n",
        "`0 is for probability of no rain` and `1 is for probability of rain.`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lf-Lec5sDvCn",
        "outputId": "923d018e-f223-4ddd-e21c-3c8deef079c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.91382428, 0.83565645, 0.82033915, ..., 0.97674285, 0.79855098,\n",
              "       0.30734161])"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# probability of getting output as 0 - no rain\n",
        "\n",
        "logreg.predict_proba(X_test)[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rl4QZXaDDvCn",
        "outputId": "cda1b053-c8e0-4659-c14b-ad5738fd72ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.08617572, 0.16434355, 0.17966085, ..., 0.02325715, 0.20144902,\n",
              "       0.69265839])"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# probability of getting output as 1 - rain\n",
        "\n",
        "logreg.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lETGfiLDvCo"
      },
      "source": [
        "# **Check accuracy score** <a class=\"anchor\" id=\"14\"></a>\n",
        "\n",
        "\n",
        "[Table of Contents](#0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGTF1I1_DvCo",
        "outputId": "b284c206-277a-4897-e2d6-994f4f877528"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model accuracy score: 0.8502\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcPOpKmBDvCo"
      },
      "source": [
        "Here, **y_test** are the true class labels and **y_pred_test** are the predicted class labels in the test-set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myVv4ROKDvCo"
      },
      "source": [
        "### Compare the train-set and test-set accuracy\n",
        "\n",
        "\n",
        "Now, I will compare the train-set and test-set accuracy to check for overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BK4CkqSTDvCo",
        "outputId": "98cdab1b-5bd5-428e-cd46-90e46b003718"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['No', 'No', 'No', ..., 'No', 'No', 'No'], dtype=object)"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_train = logreg.predict(X_train)\n",
        "\n",
        "y_pred_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZDZL4W8DvCo",
        "outputId": "94fb9fbd-3fd5-4218-fea1-fb7db9ece38e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training-set accuracy score: 0.8476\n"
          ]
        }
      ],
      "source": [
        "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-8_xpvVvNEqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UD8HDnIhNNLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jwlxr4j-NNUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q3uqJrXhNNYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SsW_Vw6qNNgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ml9LqUBzNOg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u28xZmS4NOkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IFin50MiNOmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cz1FqoRdNOwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHyS2Wk3DvCz"
      },
      "source": [
        "# **21. Results and conclusion** <a class=\"anchor\" id=\"21\"></a>\n",
        "\n",
        "\n",
        "[Table of Contents](#0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB_9t3C7DvCz"
      },
      "source": [
        "1.\tThe logistic regression model accuracy score is 0.8501. So, the model does a very good job in predicting whether or not it will rain tomorrow in Australia.\n",
        "\n",
        "2.\tSmall number of observations predict that there will be rain tomorrow. Majority of observations predict that there will be no rain tomorrow.\n",
        "\n",
        "3.\tThe model shows no signs of overfitting.\n",
        "\n",
        "4.\tIncreasing the value of C results in higher test set accuracy and also a slightly increased training set accuracy. So, we can conclude that a more complex model should perform better.\n",
        "\n",
        "5.\tIncreasing the threshold level results in increased accuracy.\n",
        "\n",
        "6.\tROC AUC of our model approaches towards 1. So, we can conclude that our classifier does a good job in predicting whether it will rain tomorrow or not.\n",
        "\n",
        "7.\tOur original model accuracy score is 0.8501 whereas accuracy score after RFECV is 0.8500. So, we can obtain approximately similar accuracy but with reduced set of features.\n",
        "\n",
        "8.\tIn the original model, we have FP = 1175 whereas FP1 = 1174. So, we get approximately same number of false positives. Also, FN = 3087 whereas FN1 = 3091. So, we get slighly higher false negatives.\n",
        "\n",
        "9.\tOur, original model score is found to be 0.8476. The average cross-validation score is 0.8474. So, we can conclude that cross-validation does not result in performance improvement.\n",
        "\n",
        "10.\tOur original model test accuracy is 0.8501 while GridSearch CV accuracy is 0.8507. We can see that GridSearch CV improve the performance for this particular model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE0Q2l2LDvC0"
      },
      "source": [
        "# **22. References** <a class=\"anchor\" id=\"22\"></a>\n",
        "\n",
        "\n",
        "[Table of Contents](#0.1)\n",
        "\n",
        "\n",
        "\n",
        "The work done in this project is inspired from following books and websites:-\n",
        "\n",
        "\n",
        "1. Hands on Machine Learning with Scikit-Learn and Tensorflow by Aurélién Géron\n",
        "\n",
        "2. Introduction to Machine Learning with Python by Andreas C. Müller and Sarah Guido\n",
        "\n",
        "3. Udemy course – Machine Learning – A Z by Kirill Eremenko and Hadelin de Ponteves\n",
        "\n",
        "4. Udemy course – Feature Engineering for Machine Learning by Soledad Galli\n",
        "\n",
        "5. Udemy course – Feature Selection for Machine Learning by Soledad Galli\n",
        "\n",
        "6. https://en.wikipedia.org/wiki/Logistic_regression\n",
        "\n",
        "7. https://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html\n",
        "\n",
        "8. https://en.wikipedia.org/wiki/Sigmoid_function\n",
        "\n",
        "9. https://www.statisticssolutions.com/assumptions-of-logistic-regression/\n",
        "\n",
        "10. https://www.kaggle.com/mnassrib/titanic-logistic-regression-with-python\n",
        "\n",
        "11. https://www.kaggle.com/neisha/heart-disease-prediction-using-logistic-regression\n",
        "\n",
        "12. https://www.ritchieng.com/machine-learning-evaluate-classification-model/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06X9VVwnDvC0"
      },
      "source": [
        "So, now we will come to the end of this kernel.\n",
        "\n",
        "I hope you find this kernel useful and enjoyable.\n",
        "\n",
        "Your comments and feedback are most welcome.\n",
        "\n",
        "Thank you\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEw0IGjbDvC0"
      },
      "source": [
        "[Go to Top](#0)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "nE0Q2l2LDvC0"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}